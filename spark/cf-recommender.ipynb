{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Capitulo 3: Recomendando Musicas utilizando el Audioscrobbler Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# En qué concisten las recomendaciones utilizando Filtros Colaborativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./imagenes/cf-01.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./imagenes/cf-02.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./imagenes/cf-03.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./imagenes/cf-04.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./imagenes/cf-05.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"./imagenes/Collaborative_filtering.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"text-align:center\">Algoritmo de factorizacion de matrices utilizado para construir el Colaborative Filtering</h3>\n",
    "<img src=\"./imagenes/mllib_rec_engine_image005.png\" style=\"width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Librerias a ser utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pyspark.mllib.recommendation import *\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import random\n",
    "from operator import *\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Se crea una sesion de spark para ejecutar los jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Se construye una SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Modelo de Recomendacion de musicas\") \\\n",
    "    .config(\"spark.executor.memory\", \"8gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Descripcion del Audioscrobbler Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "El Audioscrobbler Dataset es un dataset obtenido del sitio last.fm e incluye los siguientes archivos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"text-align:center\"> artist_data.txt :</h3>\n",
    "<p style=\"text-align:center\">Las columnas de este dataset son de la forma:<p>\n",
    "\n",
    "\n",
    "| artist_id | artist_name |\n",
    "|------|------|\n",
    "|1240105 |\tAndré Visior |\n",
    "|1240113 |\triow arai |\n",
    "|1106617 |\tBloque |\n",
    "|6776115 |\t小松正夫 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"text-align:center\">artist_alias.txt : </h3>\n",
    "<p style=\"text-align:center\">Dado que en el primer dataset, un mismo artista puede aparecer con nombres escritos de diferentes maneras, se les asigna un alias. Las columnas de este dataset son de la forma:</p>\n",
    "\n",
    "| artist_id | artist_alias |\n",
    "|------|------|\n",
    "|1027859 |\t1252408 |\n",
    "|1017615 |\t668 |\n",
    "|6745885 |\t1268522 |\n",
    "|1018110 |\t1018110 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"text-align:center\"> user_artist_data.txt : </h3>\n",
    "<p style=\"text-align:center\">Este archivo es el mas importante de todos ya que se utilizará para generar el dataset. Las columnas de este dataset son de la forma:</p>\n",
    "\n",
    "| user_id | artist_id | veces_reproducido |\n",
    "|------|------|------|\n",
    "|1059637 | 1000010 | 238 |\n",
    "|1059637 | 1000049 | 1 |\n",
    "|1059637 | 1000056 | 1 |\n",
    "|1059637 | 1000062 | 11 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preparando los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parseo de los datos\n",
    "Como los datos deben ser extraidos de un archivo txt definimos una funcion que parsea dichos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def parser(s, delimeters=\" \", to_int=None):\n",
    "    '''\n",
    "    @param: s, string a ser parseado\n",
    "    @param: delimiters, el criterio segun el cual hacer el split\n",
    "    @param: to_int, luego del split, que elementos convertir a int\n",
    "    parser parsea una entrada segun el tipo de delimitador,\n",
    "    luego si to_int contiene una lista de indices, convierte los\n",
    "    valores de s a int segun esta lista\n",
    "    '''\n",
    "    s = s.split(delimeters)\n",
    "    # si to_int es distinto de None\n",
    "    if to_int:\n",
    "        # se convierte el elemento s[i] en int donde i es un elemento de to_int\n",
    "        # el cual contiene una lista de indices de los elementos que deben ser convertidos a int\n",
    "        # sino, dicho elemento de ese no necesita ser convertido a int y se mantiene su tipo original\n",
    "        for i in to_int:\n",
    "            s[i] = int(s[i])\n",
    "    return tuple(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Se parsean los datos de los 3 archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Path que especifica donde se encuentran los datos\n",
    "dataPath = \"/home/jovyan/work/data/audioscrobbling/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Se indica de donde tomar los datos de los artistas y se hace el map que parsea los datos,\n",
    " para este dataset solo el primer elemento, que corresponde al __user_id__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "artistData = sc.textFile(dataPath+\"artist_data_small.txt\").map(lambda x: parser(x,'\\t',[0]))\n",
    "# artistData = sc.textFile(dataPath+\"artist_data.txt\").map(lambda x: parser(x,'\\t',[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Se indica de donde tomar los aliases de los artistas y se hace el map que parsea los datos.\n",
    " Tanto el __user_id__ como el __user_alias__ se deben convertir a int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "artistAlias = sc.textFile(dataPath+\"artist_alias_small.txt\").map(lambda x: parser(x,'\\t', [0,1]))\n",
    "# artistAlias = sc.textFile(dataPath+\"artist_alias.txt\").map(lambda x: parser(x,'\\t', [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Se leen los datos de los artistas y se los mapea, \n",
    " retorna pares clave-valor a artistAliasMap, como un __diccionario__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "artistAliasMap = artistAlias.collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " Se obtienen los datos de los usuarios.\n",
    " Todos los elementos de cada registro se convierten a __int__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "userArtistData = sc.textFile(dataPath+\"user_artist_data_small.txt\").map(lambda x: parser(x,' ',[0,1,2]))\n",
    "# userArtistData = sc.textFile(dataPath+\"user_artist_data.txt\").map(lambda x: parser(x,' ',[0,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Luego se obtiene un nuevo RDD donde el nombre de los artistas se\n",
    " convierten a sus alias equivalentes utilizando __get__ que \n",
    " en caso de no encontrarse el alias en el diccionario, se utiliza el valor pasado por defecto\n",
    " en este caso, el valor en si (  x [ 1 ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "userArtistData = userArtistData.map(lambda x: (x[0], artistAliasMap.get(x[1], x[1]), x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creacion de los conjuntos de datos para entrenar el modelo ALS\n",
    " El dataset userArtistData se divide de la siguiente manera\n",
    " - 90% trainingData\n",
    " - 10% testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainingData, testData = userArtistData.randomSplit([90,10], 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Se persisten los RDD con un nivel de almacenamiento predeterminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1059637, 1000010, 238), (1059637, 1000049, 1), (1059637, 1000056, 1)]\n",
      "[(1059637, 1000094, 1), (1059637, 1000112, 423), (1059637, 1000433, 10)]\n",
      "44564\n",
      "4917\n"
     ]
    }
   ],
   "source": [
    "# Visualizacion de los RDDs\n",
    "print (trainingData.take(3))\n",
    "print (testData.take(3))\n",
    "print (trainingData.count())\n",
    "print (testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Entrenamiento y Prueba del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Entrenamiento del modelo\n",
    "El algoritmo de ALS toma los siguientes hiperparametros\n",
    "- rank = 10 El numero de factores latentes en el modelo, o equivalentemente, el numero de columnas k en los parametros en las matrices de usuarios y musicas. En casos no triviales, esto tambien es su rango\n",
    "- iterations = 5 El numero de iteraciones que corre la factorizacion. Mas iteraciones toman más tiempo en computarse pero producen mejores factorizaciones\n",
    "- lambda = 0.01 Un parametro de overfitting estandar. Valores más grandes resisten el overfiting, pero valores que son muy grandes afectan negativamente la __exactitud__ de la factorizacion\n",
    "- alpha = 1.0 controla los pesos relativos de las interacciones observadas y no observadas entre usuario - producto (musica) en la factorizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "training = trainingData.map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2])))\n",
    "# cfModel = ALS.trainImplicit(training, rank=10, seed=345)\n",
    "cfModel = ALS.trainImplicit(training, rank=10, iterations=20, lambda_=0.01, blocks=-1, alpha=1.0, nonnegative=False, seed=345)\n",
    "# cfModel.save(sc, \"/home/jovyan/work/models/full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Validacion del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Curva ROC\n",
    "<img src=\"./imagenes/ROC_space-2.png\" style=\"width:60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"text-align:center\"> Para calcular el grado de acierto del modelo se calcula el Area Bajo la Curva (AUC) </h3>\n",
    "<img src=\"./imagenes/Curvas-ROC.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Se obtienen todos los artist_id y se realiza un broadcast de los mismos\n",
    "allitemIDs = userArtistData.map(lambda x: x[1]).distinct().collect()\n",
    "bAllItemIDs = sc.broadcast(allitemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Depende del numero de items en userIDAndPosItemIDs,\n",
    "# crea un conjunto de productos 'negativos' para cada usuario.\n",
    "# estos son elegidos de forma randomica\n",
    "# de entre todos los otros items, excluyendo aquellos que son\n",
    "# \"positivos para el usuario\"\n",
    "# NOTE: mapPartitions opera sobre muchos pares (usuario, item-positivo) a la vez\n",
    "# NOTE: flatMap divide las colecciones de arriba en un gran conjunto de tuplas\n",
    "def xtractNegative(userIDAndPosItemIDs):\n",
    "    def pickEnoughNegatives(line):\n",
    "        userID = line[0]\n",
    "        posItemIDSet = set(line[1])\n",
    "        negative = []\n",
    "        allItemIDs = bAllItemIDs.value\n",
    "        # Se mantienen tantos ejemplos negativos como positivos por usuario. Pueden haber duplicados\n",
    "        i = 0\n",
    "        while (i < len(allItemIDs) and len(negative) < len(posItemIDSet)):\n",
    "            itemID = allItemIDs[randint(0,len(allItemIDs)-1)]\n",
    "            if itemID not in posItemIDSet:\n",
    "                negative.append(itemID)\n",
    "            i += 1\n",
    "        \n",
    "        # El resultado es una coleccion de tuplas (usario, item-negativo)\n",
    "        return map(lambda itemID: (userID, itemID), negative)\n",
    "\n",
    "    # Se inicializa un RNG y el conjunto de IDs de objetos una vez por particion \n",
    "    return map(pickEnoughNegatives, userIDAndPosItemIDs)\n",
    "\n",
    "def ratioOfCorrectRanks(positiveRatings, negativeRatings):\n",
    "    \n",
    "    # Encuentra elementos en arr cuyo index >= start y tiene valores mas pequenios que x\n",
    "    # arr es un array ordenado\n",
    "    def findNumElementsSmallerThan(arr, x, start=0):\n",
    "        left = start\n",
    "        right = len(arr) -1\n",
    "        # si x es mayor que el elemento mas grande en arr\n",
    "        if start > right or x > arr[right]:\n",
    "            return right + 1\n",
    "        mid = -1\n",
    "        while left <= right:\n",
    "            mid = (left + right) // 2 # floordiv\n",
    "            if arr[mid] < x:\n",
    "                left = mid + 1\n",
    "            elif arr[mid] > x:\n",
    "                right = mid - 1\n",
    "            else:\n",
    "                while mid-1 >= start and arr[mid-1] == x:\n",
    "                    mid -= 1\n",
    "                return mid\n",
    "        return mid if arr[mid] > x else mid + 1\n",
    "    \n",
    "    # AUC puede ser visto como la probabilidad de que un item randomico positivo obtenga\n",
    "    # un puntaje mayor que un item randomico negativo. Aqui se computa la \n",
    "    # proporcion de todos los pares positivo-negativos que son rankeados correctamente. \n",
    "    # El resultado es igual a la metrica AUC\n",
    "    correct = 0 ## L\n",
    "    total = 0 ## L\n",
    "    \n",
    "    # ordenar positiveRatings es mas costoso\n",
    "    # positiveRatings = np.array(map(lambda x: x.rating, positiveRatings))\n",
    "\n",
    "    negativeRatings = list(map(lambda x:x.rating, negativeRatings))\n",
    "    \n",
    "    #np.sort(positiveRatings)\n",
    "    negativeRatings.sort()# = np.sort(negativeRatings)\n",
    "    total = len(positiveRatings)*len(negativeRatings)\n",
    "    \n",
    "    for positive in positiveRatings:\n",
    "        # conteo de pares correctamente rankeados\n",
    "        correct += findNumElementsSmallerThan(negativeRatings, positive.rating)\n",
    "\n",
    "    # Retorna AUC: fraccion de pares ranqueados correctamente\n",
    "    return float(correct) / total\n",
    "\n",
    "def calculateAUC(positiveData, bAllItemIDs, predictFunction):\n",
    "    # Toma los datos como 'positivos' y los mapea a tuplas\n",
    "    positiveUserProducts = positiveData.map(lambda r: (r[0], r[1]))\n",
    "    # Se realiza predicciones para todos los elementos, \n",
    "    # incluyendo una puntuacion numerica, y agrupados por usuario\n",
    "    positivePredictions = predictFunction(positiveUserProducts).groupBy(lambda r: r.user)\n",
    "    \n",
    "    # Se crea un conjunto de productos \"negativos\" para cada usuario. \n",
    "    # Estos son elegidos randomicamente de entre todos los otros items, \n",
    "    # excluyendo aquellos que son positivos para el usuario\n",
    "    negativeUserProducts = positiveUserProducts.groupByKey() \\\n",
    "                                .mapPartitions(xtractNegative).flatMap(lambda x: x)\n",
    "    # Se realizan predicciones sobre los demas\n",
    "    negativePredictions = predictFunction(negativeUserProducts).groupBy(lambda r: r.user)\n",
    "    \n",
    "    return (\n",
    "            positivePredictions.join(negativePredictions)\n",
    "                .values()\n",
    "                .map(\n",
    "                    lambda positive_negativeRatings: \\\n",
    "                    ratioOfCorrectRanks(positive_negativeRatings[0], positive_negativeRatings[1])\n",
    "                )\n",
    "                .mean()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc= 0.8073447229476185\n"
     ]
    }
   ],
   "source": [
    "auc = calculateAUC(testData, bAllItemIDs, cfModel.predictAll)\n",
    "print(\"auc=\",auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prueba del modelo con diferentes usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 0: The Starting Line\n",
      "Artist 1: From Autumn to Ashes\n",
      "Artist 2: New Found Glory\n",
      "Artist 3: Taking Back Sunday\n",
      "Artist 4: My Chemical Romance\n"
     ]
    }
   ],
   "source": [
    "recommended = map(lambda x: x.product, cfModel.recommendProducts(1059637, 5))\n",
    "for i, artist in enumerate(recommended):\n",
    "    print (\"Artist %s: %s\" % (i, artistData.lookup(artist)[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 0: Alanis Morissette\n",
      "Artist 1: Pixies\n",
      "Artist 2: The Offspring\n",
      "Artist 3: Rage Against the Machine\n",
      "Artist 4: Nirvana\n"
     ]
    }
   ],
   "source": [
    "recommended = map(lambda x: x.product, cfModel.recommendProducts(2064012, 5))\n",
    "for i, artist in enumerate(recommended):\n",
    "    print (\"Artist %s: %s\" % (i, artistData.lookup(artist)[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center\"> FIN </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "FIN DEL TP"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
